{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71887ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7af07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lyrics(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lyrics_raw = f.readlines()\n",
    "        \n",
    "    matched_lyrics = [x for x in lyrics_raw if re.search('We do not have the lyrics', x) is None]\n",
    "    \n",
    "    matched_lyrics_split = [x.split('|') for x in matched_lyrics]\n",
    "    \n",
    "    correct_length = [x for x in matched_lyrics_split if len(x) == 4]\n",
    "    \n",
    "    df = pd.DataFrame(correct_length, columns = ['lyrics', 'title_name', 'artist_name', 'clean_title'])\n",
    "    df.clean_title = df.clean_title.str.replace(r'\\n', r'', regex = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c296012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatizer(text, nlp):\n",
    "    doc = nlp(' '.join(text))\n",
    "    \n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adef18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lyrics(df, min_valid_tokens = 15):\n",
    "    processed_df = df.copy()\n",
    "    # Remove scraping artifacts\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace('^(.+\\s{4,})', r' ', regex = True, flags = re.IGNORECASE)\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace(r'\\w+:', r' ', regex = True)\n",
    "\n",
    "    # Remove non-alphabetic characters and remove words with length <= 2\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace(r'[\\W\\d]',\n",
    "                                                          r' ', regex = True)\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace(r'\\b\\w{0,2}\\b',\n",
    "                                                          r' ', regex = True)\n",
    "    # Remove header 'Song title Lyrics'\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace(r'^[\\w\\W]+ Lyrics',\n",
    "                                                          r'', regex = True)\n",
    "    # Convert all lengths of whitespace to single whitespaces, strip outer whitespaces\n",
    "    processed_df.lyrics = processed_df.lyrics.str.replace(r'\\s+',\n",
    "                                                          r' ', regex = True).str.strip()\n",
    "    # Lowercase all words\n",
    "    processed_df.lyrics = processed_df.lyrics.str.lower()\n",
    "    # Reconvert to list\n",
    "    processed_df.lyrics = processed_df.lyrics.apply(lambda x: word_tokenize(x))\n",
    "    # Remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    processed_df.lyrics = processed_df.lyrics.apply(lambda x:\\\n",
    "                                            [word for word in x if word not in stop_words])\n",
    "    # Keep records with a minimum number of tokens\n",
    "    processed_df = processed_df.loc[processed_df.lyrics.apply(lambda x: len(x)) >= min_valid_tokens]\n",
    "    # Lemmatization\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    processed_df.lyrics = processed_df.lyrics.apply(lambda x: spacy_lemmatizer(x, nlp))\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3205dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_process_lyrics(files, min_valid_tokens = 15):\n",
    "    if type(files) == str:\n",
    "        df = extract_lyrics(files)\n",
    "        processed_df = process_lyrics(df, min_valid_tokens)\n",
    "        \n",
    "        return processed_df\n",
    "    elif type(files) == list:\n",
    "        dfs = [process_lyrics(extract_lyrics(file), min_valid_tokens) for file in files]\n",
    "        processed_df = pd.concat(dfs, axis = 0)\n",
    "        \n",
    "        return processed_df\n",
    "    else:\n",
    "        print('Must input a single file string or a list of file strings.')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbed64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_lyrics_and_metadata_frames(lyrics_df, metadata_df):\n",
    "    merged_df = metadata_df.merge(lyrics_df, how = 'inner', on = ['title_name', 'artist_name'])\n",
    "    merged_df = merged_df.drop(['title_id', 'genre_id', 'album_id', 'album_name', 'artist_id'], axis = 1)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3cdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(lyric_files, metadata_file, dest_file, min_valid_tokens = 15):\n",
    "    lyrics_df = extract_and_process_lyrics(lyric_files, min_valid_tokens)\n",
    "    \n",
    "    columns = ['title_id', 'title_name', 'genre_id', 'genre_name', 'album_id', 'album_name', 'artist_id', 'artist_name']\n",
    "    metadata_df = pd.read_csv(metadata_file, sep = '\\t', header = None)\n",
    "    metadata_df.columns = columns\n",
    "    \n",
    "    merged_df = stitch_lyrics_and_metadata_frames(lyrics_df, metadata_df)\n",
    "    merged_df = merged_df.drop_duplicates(subset = ['title_name', 'artist_name'])\n",
    "    \n",
    "    merged_df.to_parquet(dest_file)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9512b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lyrics_file = '../data/raw/songlyrics_lyrics_merged.csv'\n",
    "metadata_file = '../data/raw/music_data.tsv'\n",
    "dest_file = '../data/cleaned/tokenized_data_complete.parquet'\n",
    "merged_data_all_from_source = process_data(song_lyrics_file, metadata_file, dest_file, min_valid_tokens = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec9d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
